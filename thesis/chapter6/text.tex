% Text for chapter 6
\chapter{Predicting Diagnostics for Nanoflares of Varying Frequency}\label{ch:modeling-observables}
\thispagestyle{firstpageofchapterstyle}

In this chapter, I use the forward modeling pipeline outlined in \autoref{ch:synthesizar} to predict observable signatures of an \AR{} heated by nanoflares of varying frequency. In particular, I predict both the emission measure slope (see \autoref{sec:em_slope}) and time lag (see \autoref{sec:timelag}). In \autoref{ch:classifying-observables}, these simulated diagnostics are used to train a random forest classifier to predict heating frequency in every pixel of \AR{} NOAA 1158. This chapter is adapted directly from \citet{barnes_understanding_2019} which has recently been submitted for publication. 

\section{Introduction}\label{sec:modeling-observables:introduction}

Nanoflares have long been used to explain the observed million-degree temperatures in the non-flaring solar corona. Though originally pertaining to energetic bursts of order $10^{24}$ erg resulting from small-scale reconnection \citep{parker_nanoflares_1988}, the term \textit{nanoflare} is now synonymous with any impulsive energy release and is not specific to any particular physical mechanism \citep{klimchuk_key_2015}. Due to their faint, transient nature, direct observations of nanoflares are made difficult by several factors, including inadequate spectral coverage of instruments, the efficiency of thermal conduction, and non-equilibrium ionization \citep{cargill_implications_1994,winebarger_defining_2012,barnes_inference_2016}. However, recent observations of ``very hot'' \SIrange{8}{10}{\mega\kelvin} plasma, the so-called ``smoking gun'' of nanoflares, have provided compelling evidence for their existence \citep[e.g.][]{brosius_pervasive_2014,caspi_new_2015,parenti_spectroscopy_2017,ishikawa_detection_2017}.

Critical to understanding the underlying heating mechanism is knowing whether the corona in non-flaring active regions is heated \textit{steadily} or \textit{impulsively}, or, more precisely, at what frequency do nanoflares repeat on a given magnetic strand. In the case of low-frequency nanoflares, the time between consecutive events on a strand is long relative to its characteristic cooling time, giving the strand time to fully cool and drain before it is re-energized. In the high-frequency scenario, the time between events is short relative to the cooling time such that the strand is not allowed to fully cool before being heated again. Steady heating may be regarded as nanoflare heating in the very high-frequency limit.

Before proceeding, I note that a magnetic \textit{strand}, the fundamental unit of the low-$\beta$ corona, is a flux tube oriented parallel to the magnetic field that is isothermal in the direction perpendicular to the magnetic field. I make the distinction that a \textit{coronal loop} is an observationally-defined feature representing a magnetic field-aligned intensity enhancement relative to the surrounding diffuse emission such that a single coronal loop may be composed of many thermally-isolated strands. Furthermore, I define the \AR{} \textit{core} as the area near the center of the \AR{} whose X-ray and EUV emission is dominated by closed loops with both footpoints rooted in the photosphere.

In lieu of a direct observable signature of nanoflare heating, two parameters in particular have been used to diagnose the heating frequency in \AR{} cores: the emission measure slope and the time lag. These diagnostics provide \textit{indirect} signatures of the energy deposition via observations of the plasma cooling by thermal conduction, enthalpy, and radiation. I will now discuss each of these observables in detail.

The emission measure distribution, $\mathrm{EM}(T)=\int\mathrm{d}h\,n_e^2$, where $n_e$ is the electron density and the integration is taken along the LOS, is a useful diagnostic for parameterizing the frequency of energy deposition (see \autoref{sec:dem} for an extended discussion of the emission measure distribution). Many observational and theoretical studies have suggested that the ``cool'' portion of the $\emd$ (i.e. leftward of the peak, $10^{5.5}\lesssim T\lesssim10^{6.5}$ K), can be described by $\mathrm{EM}(T)\sim T^a$ \citep{jordan_structure_1976,cargill_implications_1994,cargill_nanoflare_2004}. The so-called \textit{emission measure slope}, $a$, is an important diagnostic for assessing how often a single strand may be reheated and has been used by several researchers to interpret \AR{} core observations in terms of both high- and low-frequency heating (see \autoref{tab:em_slope} and references therein). The ``cool'' emission measure slope typically falls in the range $2<a<5$, with shallower slopes indicative of low-frequency heating and steeper slopes associated with high-frequency heating. Many observational studies of active region cores have used the emission measure slope to make conclusions about the heating frequency \citep[e.g.][]{tripathi_emission_2011,warren_constraints_2011,winebarger_using_2011,schmelz_cold_2012,warren_systematic_2012,del_zanna_evolution_2015}. The emission measure slope is discussed extensively in \autoref{sec:em_slope}.

To better understand observable properties of nanoflare heating, several researchers have used hydrodynamic models of coronal loops to examine how the emission measure slope varies with heating frequency \citep{mulu-moore_can_2011,bradshaw_diagnosing_2012,reep_diagnosing_2013}. Most recently, \citet{cargill_active_2014} found that varying the time between consecutive heating events from \SI{250}{\second} (high-frequency heating) to \SI{5000}{\second} (low-frequency heating) could account for the wide observed distribution of emission measure slopes, with higher values of $a$ corresponding to higher heating frequency due to the $\emd$ distribution becoming increasingly isothermal \citep[see also][]{barnes_inference_2016-1}.

In addition to the emission measure slope, the time lag analysis of \citet{viall_evidence_2012} has also been used by several workers to understand the frequency of energy release in \AR{} cores. The \textit{time lag} is the temporal delay which maximizes the cross-correlation between two time series, and, qualitatively, can be thought of as the amount of time which one signal must be shifted relative to another in order to achieve the best ``match'' between the two signals. As the plasma cools through the six EUV channels of AIA, the intensity will peak in successively cooler passbands of the instrument according to the sensitivity of each channel in temperature space \citep{viall_patterns_2011}. Computing the time lag between light curves in different channels provides a proxy for the cooling time between channels and insight into the thermal evolution of the plasma. Calculating the time lag in each pixel of an AIA image can reveal large scale cooling patterns in coronal loops as well as the diffuse emission between loops across an entire \AR{}.

\citet{viall_evidence_2012} computed time lags for all possible AIA EUV channel pairs in every pixel of \AR{} NOAA 11082 and found positive time lags across the entire \AR{} core, indicative of cooling plasma. They interpreted these observations as being inconsistent with a steady heating model. \citet{viall_survey_2017} extended this analysis to the 15 active regions catalogued by \citet{warren_systematic_2012} and found overwhelmingly positive time lags, or cooling plasma, in all cases, with only a few isolated instances of negative time lags, or heating plasma. These observations are consistent with an impulsive heating scenario in which little emission is produced during the heating phase because of the time needed to fill the corona by chromospheric evaporation and the efficiency of thermal conduction. \citet{bradshaw_patterns_2016} predicted AIA intensities for a range of nanoflare heating frequencies in a model \AR{} and applied the time-lag analysis to their simulated images. They found that aspects of both high and intermediate frequency nanoflares reproduced the observed time-lag patterns, but neither model could fully account for the observational constraints, suggestive of a range of heating frequencies across the \AR{}. However, \citet{lionello_can_2016} used a field-aligned hydrodynamic model to compute time lags for several loops in NOAA 11082 and concluded that an impulsive heating model could not account for the long ($>5000$ s) time lags calculated from observations by \citet{viall_evidence_2012}.

Any successful heating model must be able to reproduce the observed distribution of emission measure slopes and time lags. In order to carry out such a test, both advanced forward modeling and sophisticated comparisons to data are required. In this chapter, I carry out a series of nanoflare heating simulations in order to better understand how the frequency of impulsive heating events on a given strand is related to observable properties of the plasma, notably the emission measure slope and the time lag as derived from AIA observations. To do this, I use a combination of magnetic field extrapolations, hydrodynamic models, and atomic data to produce simulated AIA emission which can be treated in the same manner as real observations. I then apply the emission measure and time-lag analysis to this simulated data. \autoref{sec:modeling-observables:modeling} provides detailed descriptions of the forward modeling pipeline and the nanoflare heating model. In \autoref{sec:modeling-observables:results}, I show the predicted intensities for each heating model and AIA channel (\autoref{sec:modeling-observables:intensities}), the resulting emission measure slopes (\autoref{sec:modeling-observables:em_slopes}) and the time lags (\autoref{sec:modeling-observables:timelags}). \autoref{sec:modeling-observables:discussion} provides some discussion of the results and \autoref{sec:modeling-observables:conclusions} includes a summary and concluding remarks.

This chapter serves to describe the forward modeling procedure and lay out the results of the nanoflare simulations for each heating frequency. In \autoref{ch:classifying-observables}, I use machine learning to make detailed comparisons to AIA observations of \AR{} NOAA 1158. I train a random forest classifier using the predicted emission measure slopes and time lags presented here over the entire heating frequency parameter space in order to classify the heating frequency in each pixel of the observed \AR{}. In contrast to past studies which have relied on a single diagnostic, this approach simultaneously accounts for an arbitrarily large number of observables in deciding which model fits the data ``best.'' The ability to compare models with large quantities of data statistically is crucial for progress in the current era where the amount of solar coronal data is orders of magnitude larger than in the past.  Combined, these two chapters demonstrate a novel method for using real and simulated observations to systematically predict heating properties in \AR{} cores.

\section{Modeling}\label{sec:modeling-observables:modeling}

% spell-checker: disable %
\begin{pycode}[chapter6_modeling]
name = 'chapter6'
ch6_modeling = texfigure.Manager(
    pytex,
    os.path.join('.', name),
    number=6,
    **{k: os.path.join('.', name, v) for k,v in manager_opts.items()}
)
from sunpy.instr.aia import aiaprep
from sunpy.physics.differential_rotation import diffrot_map
\end{pycode}
% spell-checker: enable %

In order to understand how signatures of the heating frequency are manifested in the emission measure slope and time lag, I predict the emission over the entire \AR{} as observed by AIA for a range of nanoflare heating frequencies. To do this, I have constructed an advanced forward modeling pipeline through a combination of magnetic field extrapolations, field-aligned hydrodynamic simulations, and atomic data. In the following section, I discuss each step of the pipeline. Additionally, this forward modeling code is discussed in greater detail in \autoref{ch:synthesizar}.

\subsection{Magnetic Field Extrapolation}\label{sec:modeling-observables:field}

% spell-checker: disable %
\begin{pycode}[chapter6_modeling]
# Data prep
aia_map = Map(ch6_modeling.data_file('aia_171_observed.fits'))
hmi_map = Map(ch6_modeling.data_file('hmi_magnetogram.fits'))
# AIA
aia_map = diffrot_map(aiaprep(aia_map), time=hmi_map.date, rot_type='snodgrass')
aia_map = aia_map.submap(
    SkyCoord(-440, -375, unit=u.arcsec, frame=aia_map.coordinate_frame),
    SkyCoord(-140, -75, unit=u.arcsec, frame=aia_map.coordinate_frame),
)
# HMI
hmi_map = hmi_map.rotate(order=3)
hmi_map = aiaprep(hmi_map).submap(aia_map.bottom_left_coord, aia_map.top_right_coord)

# Create figure
fig = plt.figure(figsize=texfigure.figsize(
    pytex,
    scale=1,
    height_ratio=0.5,       
))
plt.subplots_adjust(wspace=0.03)

# Plot HMI Map
ax = fig.add_subplot(121, projection=hmi_map)
hmi_map.plot(
    title=False, annotate=False, axes=ax,
    norm=matplotlib.colors.SymLogNorm(50, vmin=-7.5e2, vmax=7.5e2),
    cmap='better_RdBu_r'
)
ax.grid(alpha=0)
# HPC Axes
lon,lat = ax.coords[0],ax.coords[1]
lat.set_ticklabel(rotation='vertical')
lon.set_axislabel(r'Helioprojective Longitude',)
lat.set_axislabel(r'Helioprojective Latitude',)
# HGS Axes
hgs_lon,hgs_lat = aia_map.draw_grid(axes=ax, grid_spacing=10*u.deg, alpha=0.5, color='k')
hgs_lat.set_axislabel_visibility_rule('labels')
hgs_lon.set_axislabel_visibility_rule('labels')
hgs_lat.set_ticklabel_visible(False)
hgs_lon.set_ticklabel_visible(False)
hgs_lat.set_ticks_visible(False)
hgs_lon.set_ticks_visible(False)

# Plot AIA Map
ax = fig.add_subplot(122, projection=aia_map,)
aia_map.plot(
    title=False,annotate=False, axes=ax,
    norm=ImageNormalize(vmin=0, vmax=5e3, stretch=AsinhStretch(0.1)))
# Plot fieldlines
ar = synthesizAR.Field.restore(os.path.join(ch6_modeling.data_dir, 'base_noaa1158'), lazy=False)
for l in ar.loops[::10]:
    c = l.coordinates.transform_to(aia_map.coordinate_frame)
    ax.plot_coord(c, '-', color='w', lw=0.5, alpha=0.25)
ax.grid(alpha=0)
# HMI Contours
hmi_map.draw_contours(u.Quantity([-5,5], '%'), axes=ax,
                      colors=[DEEP_PALETTE[0], DEEP_PALETTE[3]], linewidths=0.75)
# HPC Axes
lon,lat = ax.coords[0],ax.coords[1]
lon.set_ticks(color='w')
lat.set_ticks(color='w')
lat.set_ticklabel_visible(False)
lon.set_axislabel('')
lat.set_axislabel_visibility_rule('labels')
# HGS Axes
hgs_lon,hgs_lat = aia_map.draw_grid(axes=ax,grid_spacing=10*u.deg,alpha=0.5,color='w')
hgs_lat.set_axislabel_visibility_rule('labels')
hgs_lon.set_axislabel_visibility_rule('labels')
hgs_lat.set_ticklabel_visible(False)
hgs_lon.set_ticklabel_visible(False)
hgs_lat.set_ticks_visible(False)
hgs_lon.set_ticks_visible(False)

# Save
tfig = ch6_modeling.save_figure('modeling-observables:magnetogram', fext='.pdf')
tfig.caption = r'Active region NOAA 1158 on 12 February 2011 15:32:42 UTC as observed by HMI (left) and the \SI{171}{\angstrom} channel of AIA (right). The gridlines show the heliographic longitude and latitude. The left panel shows the LOS magnetogram and the colorbar range is $\pm\SI{750}{\gauss}$ on a symmetrical log scale. In the right panel, 500 out of the total 5000 field lines are overlaid in white and the red and blue contours show the HMI LOS magnetogram at the $+5\%$ (red) and $-5\%$ (blue) levels.'
\end{pycode}
\py[chapter6_modeling]|tfig|
% spell-checker: enable %

I choose \AR{} NOAA 1158, as observed by the Helioseismic Magnetic Imager \citep[HMI,][]{hoeksema_helioseismic_2014} on 12 February 2011 15:32:42 UTC, from the list of active regions studied by \citet{warren_systematic_2012}. The LOS magnetogram is shown in the left panel of \autoref{fig:modeling-observables:magnetogram}. The geometry of \AR{} NOAA 1158 is modeled by computing the three-dimensional magnetic field using the oblique potential field extrapolation method of \citet{schmidt_observable_1964} as outlined in \citet[Section 3]{sakurai_greens_1982}. The extrapolation technique of \citeauthor{schmidt_observable_1964} is well-suited for this purpose due to its simplicity and efficiency though it is only applicable on the scale of an \AR{}. The oblique correction is included to account for the fact that the \AR{} is off of disk-center. 

The HMI LOS magnetogram provides the lower boundary condition of the vector magnetic field (i.e. $B_z(x,y,z=0)$) for the field extrapolation. I crop the magnetogram to an area of \SI{300}{\arcsecond}-by-\SI{300}{\arcsecond} centered on $(\py[chapter6_modeling]|f'{ar.magnetogram.center.Tx.value:.2f}'|\si{\arcsecond},\py[chapter6_modeling]|f'{ar.magnetogram.center.Ty.value:.2f}'|\si{\arcsecond})$ and resample the image to 100-by-100 pixels to reduce the computational cost of the field extrapolation. The extrapolated field has a dimension of 100 pixels and spatial extent of $0.3R_{\solar}$ in the $z-$direction such that each component of the vector magnetic field, $\vec{B}$, has dimensions $(100,100,100)$.

% spell-checker: disable %
\begin{pycode}[chapter6_modeling]
fig = plt.figure(figsize=texfigure.figsize(
    pytex,
    scale=0.85,
    height_ratio=0.75,
))
ax = fig.gca()
vals,bins,_ = ax.hist(
    [l.full_length.to(u.Mm).value for l in ar.loops[:]],
    bins='scott', color='k', histtype='step', lw=plt.rcParams['lines.linewidth'])
ax.set_xlabel(r'$L$ $[\si{\mega\m}]$');
ax.set_ylabel(r'Number of Loops');
ax.set_ylim(1,1300)
ax.set_xlim(1,260)
# Spines
tfig = ch6_modeling.save_figure('modeling-observables:loops', fext='.pgf')
tfig.caption = r'Distribution of footpoint-to-footpoint lengths (in \si{\mega\m}) of the 5000 field lines traced from the field extrapolation computed from the magnetogram of NOAA 1158.'
tfig.figure_width = r'0.85\textwidth'
\end{pycode}
\py[chapter6_modeling]|tfig|
% spell-checker: enable %

After computing the three-dimensional vector field from the observed magnetogram, $5\times10^3$ field lines are traced through the extrapolated volume using the streamline tracing functionality in the yt software package \citep{turk_yt_2011}. Only closed field lines in the range $\SI{20}{\mega\m}<L<\SI{300}{\mega\m}$ are chosen, where $L$ is the full length of the field line. The right panel of \autoref{fig:modeling-observables:magnetogram} shows a subset of the traced field lines overlaid on the observed AIA \SI{171}{\angstrom} image of NOAA 1158. Contours from the observed HMI LOS magnetogram are shown in red (positive) and blue (negative). A qualitative comparison between the extrapolated field lines and the loops visible in the AIA \SI{171}{\angstrom} image reveals that the field extrapolation and line tracing adequately capture the three-dimensional geometry of the \AR{}. \autoref{fig:modeling-observables:loops} shows the distribution of footpoint-to-footpoint lengths for all of the traced field lines.

\subsection{Hydrodynamic Modeling}\label{sec:modeling-observables:loops}

Due to the low-$\beta$ nature of the corona, each field line traced from the field extrapolation can be treated as a thermally-isolated strand. I use the Enthalpy-based Thermal Evolution of Loops model \citep[EBTEL,][]{klimchuk_highly_2008,cargill_enthalpy-based_2012,cargill_enthalpy-based_2012-1}, specifically the two-fluid version of EBTEL \citep{barnes_inference_2016}, to model the thermodynamic response of each strand. The two-fluid EBTEL code solves the time-dependent, two-fluid hydrodynamic equations spatially-integrated over the corona for the electron pressure and temperature, ion pressure and temperature, and density. The two-fluid EBTEL model accounts for radiative losses in both the transition region and corona, thermal conduction (including flux limiting), and binary Coulomb collisions between electrons and ions. The time-dependent heating input is configurable and can be deposited in the electrons and/or ions. A detailed description of the model and a complete derivation of the two-fluid EBTEL equations can be found in \autoref{sec:ebtel-two-fluid}.

For each of the $5\times10^3$ strands, a separate instance of the two-fluid EBTEL code is run for $3\times10^4$ s of simulation time in order to model the time-dependent, spatially-averaged coronal temperature and density. For each simulation, the loop length is determined from the field extrapolation. Flux limiting, with a flux limiter constant of $f=1$, is included in the heat flux calculation \citep[see Eqs. 21 and 22 of][and \autoref{hot-plasma:subsec:hf_theory}]{klimchuk_highly_2008}. Additionally, all of the energy is deposited into the electrons. To map the results back to the extrapolated field lines, a single temperature and density is assigned to every point along the strand at each time step. Though EBTEL only computes spatially-averaged quantities in the corona, its efficiency allows for the calculation of time-dependent solutions for many thousands of strands in a matter of minutes.

\subsection{Heating Model}\label{sec:modeling-observables:heating}

The heating input is parameterized in terms of discrete heating pulses on a single strand with triangular profiles of duration $\tau_{\textup{event}}=200$ s. For each event $i$, there are two parameters: the peak heating rate $q_i$ and the waiting time prior to the event $\twait[,i]$. The waiting time is defined such that $\twait[,i]$ is the amount of time between when event $i-1$ ends and event $i$ begins. Following the approach of \citet{cargill_active_2014}, the waiting time and the event energy are related such that $\twait[,i]\propto q_i$. The physical motivation for this scaling is as follows. In the nanoflare model of \citet{parker_nanoflares_1988}, random convective motions continually stress the magnetic field rooted in the photosphere, leading to the buildup and eventual release of energy. If the field is stressed for a long amount of time without relaxation, large discontinuities will have time to develop in the field, leading to a dramatic release of energy. Conversely, if the field relaxes quickly, there is not enough time for the field to become sufficiently stressed and the resulting energy release will be relatively small. 

In this chapter I explore three different heating scenarios: low-, intermediate-, and high-frequency nanoflares. I define the heating frequency in terms of the ratio between the fundamental cooling timescale due to thermal conduction and radiation, $\tau_{\textup{cool}}$, and the average waiting time of all events on a given strand, $\langle \twait\rangle$,

\begin{equation}\label{eq:modeling-observables:heating_types}
    \varepsilon = \frac{\langle \twait\rangle}{\tau_{\textup{cool}}}
    \begin{cases} 
        < 1, &  \text{high frequency},\\
        \sim1, & \text{intermediate frequency}, \\
        > 1, & \text{low frequency}.
     \end{cases}
\end{equation}

The heating frequency is parameterized in terms of the cooling time rather than an absolute waiting time as $\tau_{\textup{cool}}\sim L$ \citep[see appendix of][]{cargill_active_2014}. While a waiting time of 2000 s might correspond to low-frequency heating for a 20 Mm strand, it would correspond to high-frequency heating in the case of a 150 Mm strand. Parameterizing the heating in this way ensures that all strands in the \AR{} are heated at the same frequency relative to their cooling time. \autoref{fig:modeling-observables:hydro-profiles} shows the heating rate, electron temperature, and density as a function of time, for a single strand, for the three heating scenarios listed above.

% spell-checker: disable %
\begin{pycode}[chapter6_modeling]
fig,axes = plt.subplots(
    3, 1, sharex=True,
    figsize=texfigure.figsize(
        pytex,
        height_ratio=0.75,
    )
)
plt.subplots_adjust(hspace=0.)

i_loop=680
heating = ['high_frequency', 'intermediate_frequency','low_frequency']
loop = ar.loops[i_loop]
for i,h in enumerate(heating):
    loop.parameters_savefile = os.path.join(ch6_modeling.data_dir, f'{h}', 'loop_parameters.h5')
    with h5py.File(loop.parameters_savefile, 'r') as hf:
        q = np.array(hf[f'loop{i_loop:06d}']['heating_rate'])
    axes[0].plot(loop.time, 1e3*q, color=PALETTE[i], label=h.split('_')[0].capitalize(),)
    axes[1].plot(loop.time, loop.electron_temperature[:,0].to(u.MK), color=PALETTE[i],)
    axes[2].plot(loop.time, loop.density[:,0]/1e9, color=PALETTE[i],)

# Legend
axes[0].legend(ncol=3, loc="lower center", bbox_to_anchor=(0.5,1.02), frameon=False,)

# Labels and limits
axes[0].set_xlim(0,3e4)
axes[0].set_yticks([5,15,25])
axes[0].set_ylim(0,27)
axes[1].set_ylim(0.1,8)
axes[1].set_yticks([2,4,6,8])
axes[2].set_ylim(0,2)
axes[0].set_ylabel(r'$Q$ $[\SI[per-mode=fraction]{e-3}{\erg\per\cubic\cm\per\second}]$')
axes[1].set_ylabel(r'$T_e$ $[\si{\mega\kelvin}]$')
axes[2].set_ylabel(r'$n$ $[\SI{e9}{\per\cubic\cm}]$')
axes[2].set_xlabel(r'$t$ $[\si{\second}]$')

# Save
tfig = ch6_modeling.save_figure('modeling-observables:hydro-profiles', fext='.pgf')
tfig.caption = r'Heating rate (top), electron temperature (middle), and density (bottom) as a function of time for the three heating scenarios for a single strand. The colors denote the heating frequency as defined in the legend. The strand has a half length of $L/2\approx\SI{40}{\mega\m}$ and a mean field strength of $\bar{B}\approx\SI{30}{\gauss}$.'
\end{pycode}
\py[chapter6_modeling]|tfig|
% spell-checker: enable %

For a single impulsive event $i$ with a triangular temporal profile of duration $\tau_{\textup{event}}$, the energy density is $E_i=\tau_{\textup{event}}q_i/2$. Summing over all events on all strands that comprise the \AR{} gives the total energy flux injected into the \AR{},
\begin{equation}
    F_{AR} = \frac{\tau_{\textup{event}}}{2}\frac{\sum_l^{N_{\textup{strands}}}\sum_i^{N_l} q_iL_l}{t_\textup{total}}
\end{equation}
where $t_\textup{total}$ is the total simulation time, $N_\textup{strands}$ is the total number of strands comprising the \AR{}, and $N_l=(t_\textup{total} + \langle\twait\rangle)/(\tau + \langle\twait\rangle)$ is the total number of events occurring on each strand over the whole simulation. Note that the number of events per strand is a function of both $\varepsilon$ and $\tau_{\textup{cool}}$.

For each heating frequency, the total flux into the \AR{} is constrained by $F_{\ast}=\SI{e7}{\erg\per\square\cm\per\second}$ \citep{withbroe_mass_1977} such that $F_{AR}$ must satisfy the condition,
\begin{equation}\label{eq:modeling-observables:energy_constraint}
    \frac{| F_{AR}/N_\textup{strands} - F_{\ast} |}{F_{\ast}} < \delta,
\end{equation}
where $\delta\ll1$. For each strand, $N_l$ events, each with energy $E_i$, are chosen from a power-law distribution with slope $-2.5$. The upper bound of the distribution is fixed to be $\bar{B}_l^2/8\pi$, where $\bar{B}_l$ is the spatially-averaged field strength along the strand $l$ as derived from the field extrapolation. This is the maximum amount of energy made available by the field to heat the strand. The lower bound on the power-law distribution for $E_i$ is then iteratively adjusted until \autoref{eq:modeling-observables:energy_constraint} is satisfied within some numerical tolerance. Note that the set of $E_i$ chosen for each strand may not uniquely satisfy \autoref{eq:modeling-observables:energy_constraint}.

The field strength derived from the potential field extrapolation is used to constrain the energy input to the EBTEL model for each strand. While the derived potential field is already in its lowest energy state and thus has no energy to give up, the goal here is only to understand how the distribution of field strength may be related to the properties of the heating. In this way, the potential field is used as a proxy for the non-potential component of the coronal field, with the understanding that no quantitative conclusions can be made regarding the amount of available energy or the stability of the field itself.

\begin{table}
    \centering
    \caption{All three heating models plus the two single-event control models. In the single-event models, the energy flux is not constrained by \autoref{eq:modeling-observables:energy_constraint}.\label{tab:modeling-observables:heating}}
    \begin{tabularx}{\columnwidth}{CCC}
        \toprule
        Name & $\varepsilon$ (see \autoref{eq:modeling-observables:heating_types}) & Energy Constrained? \\
        \midrule
        high & 0.1 & yes \\
        intermediate & 1 & yes \\
        low & 5 & yes \\
        cooling & 1 event per strand & no \\
        random & 1 event per strand & no \\
        \bottomrule
    \end{tabularx}
\end{table}

In addition to these three multi-event heating models, I also run two single-event control models. In both control models every strand in the \AR{} is heated exactly once by an event with energy $\bar{B}_l^2/8\pi$. In the first control model, the start time of every event is $t=0$ s such that all strands are allowed to cool uninterrupted for $t_\textup{total}=10^4$ s. In the second control model, the start time of the event on each strand is chosen from a uniform distribution over the interval $[0, 3\times10^4]$ s, such that the heating is likely to be out of phase across all strands. In these two models, the energy has not been constrained according to \autoref{eq:modeling-observables:energy_constraint} and the total flux into the \AR{} is $(\sum_{l}\bar{B}_l^2L_l)/8\pi t_\textup{total}$. From here on, I will refer to these two models as the ``cooling'' and ``random'' models, respectively. All five heating scenarios are summarized in \autoref{tab:modeling-observables:heating}.

\subsection{Forward Modeling}\label{sec:modeling-observables:forward}

\subsubsection{Atomic Physics}\label{sec:modeling-observables:atomic}

For an optically-thin, high-temperature, low-density plasma, the radiated power per unit volume, or \textit{emissivity}, of a transition $\lambda_{ij}$ of an electron in ion $k$ of element $X$ is given by,
\begin{equation}\label{eq:modeling-observables:ppuv}
    P(\lambda_{ij}) = \frac{n_H}{n_e}\mathrm{Ab}(X)N_j(X,k)f_{X,k}A_{ji}\Delta E_{ji}n_e,
\end{equation}
where $N_j$ is the fractional energy level population of excited state $j$, $f_{X,k}$ is the fractional population of ion $k$, $\mathrm{Ab}(X)$ is the abundance of element $X$ relative to hydrogen, $n_H/n_e\approx0.83$ is the ratio of hydrogen and electron number densities, $A_{ji}$ is the Einstein coefficient, and $\Delta E_{ji}=hc/\lambda_{ij}$ is the energy of the emitted photon \citep[see][]{mason_spectroscopic_1994,del_zanna_solar_2018}. To compute \autoref{eq:modeling-observables:ppuv}, I use version 8.0.6 of the CHIANTI atomic database \citep{dere_chianti_1997,young_chianti_2016} and the abundances of \citet{feldman_potential_1992} as provided by CHIANTI. For each atomic transition, $A_{ji}$ and $\lambda_{ji}$ can be looked up in the database. To find $N_j$, the level-balance equations for ion $k$ must be solved. The relevant excitation and de-excitation processes as provided by CHIANTI \citep[see section 3.3 of][]{del_zanna_solar_2018} are included. See \autoref{sec:line_formation} for a detailed explanation of the emissivity calculation.

The ion population fractions, $f_{X,k}$, provided by CHIANTI assume ionization equilibrium (i.e. the ionization and recombination rates are always in balance). However, in the rarefied solar corona, where the plasma is likely heated impulsively, it is not guaranteed that the ionization timescale is less than the heating timescale such that the ionization state may not be representative of the electron temperature \citep{bradshaw_explosive_2006,reale_nonequilibrium_2008,bradshaw_numerical_2009}. To properly account for this effect, $f_{X,k}$ is computed by solving \autoref{eq:population_fraction}, the time-dependent ion population equations, for each element using the ionization and recombination rates provided by CHIANTI. The details of this calculation are provided in \autoref{ap:nonequilibrium_implicit}. See \autoref{sec:nei} for a more in-depth discussion of non-equilibrium charge states.

\subsubsection{Instrument Effects}\label{sec:modeling-observables:instrument}

% spell-checker: disable %
\begin{pycode}[chapter6_modeling]
em = synthesizAR.atomic.EmissionModel.restore(
    os.path.join(ch6_modeling.data_dir, 'base_emission_model.json'))
data = {'Element': [], 'Number of Ions': [], 'Number of Transitions': [],}
for i in em:
    if not hasattr(i.transitions, 'wavelength'):
        continue
    data['Element'].append(i.atomic_symbol)
    data['Number of Ions'].append(1)
    data['Number of Transitions'].append(i.transitions.wavelength.shape[0])
df = pd.DataFrame(data=data).groupby('Element').sum().reset_index()
z = df['Element'].map(plasmapy.atomic.atomic_number)
df = df.assign(z = z).sort_values(by='z', axis=0).drop(columns='z')
caption = r"Elements included in the calculation of \autoref{eq:modeling-observables:intensity}. For each element, all ions for which CHIANTI provides sufficient data for computing the emissivity are included.\label{tab:modeling-observables:elements}"
with io.StringIO() as f:
    astropy.io.ascii.write(
        Table.from_pandas(df),
        format='latex',
        latexdict = {'data_start':r'\midrule', 'data_end': r'\bottomrule',
                     'header_start': r'\toprule', 'col_align': 'ccc',
                     'preamble':r'\begin{center}', 'tablefoot':r'\end{center}'},
        caption=caption,
        output=f)
    tab = f.getvalue()
\end{pycode}
\py[chapter6_modeling]|tab|
% spell-checker: enable %

\autoref{eq:modeling-observables:ppuv} is combined with the wavelength response function of the instrument to model the intensity as it would be observed by AIA,
\begin{equation}\label{eq:modeling-observables:intensity}
    I_c = \frac{1}{4\pi}\sum_{\{ij\}}\int_{\text{LOS}}\mathrm{d}hP(\lambda_{ij})R_c(\lambda_{ij})
\end{equation}
where $I_c$ is the intensity for a given pixel in channel $c$, $P(\lambda_{ij})$ is the emissivity as given by \autoref{eq:modeling-observables:ppuv}, and $R_c$ is the wavelength response function of the instrument for channel $c$ \citep[see \autoref{fig:aia-wavelength-response} and][]{boerner_initial_2012}. Additionally, $\{ij\}$ is the set of all atomic transitions listed in \autoref{tab:modeling-observables:elements} and the integration is along the LOS. 

% spell-checker: disable %
\begin{pycode}[chapter6_modeling]
fig,axes = plt.subplots(
    2, 3, sharex=True, sharey=True,
    figsize=texfigure.figsize(
        pytex, 
        scale=1,
        height_ratio=2/3,       
    )
)

# Setup parameters
aia = InstrumentSDOAIA([0,1]*u.s, observer_coordinate=None)
T = np.logspace(5,8,100)
p = 10**(15)*u.K/(u.cm**3)
const_p_indices = np.array([(i,np.argmin(np.fabs(em.density.value-d.value))) 
                            for i,d in enumerate(p/em.temperature)])

# Read and plot data
with h5py.File(os.path.join(ch6_modeling.data_dir, 'effective_aia_response.h5'), 'r') as hf:
    for i, (ax, channel) in enumerate(zip(axes.flatten(), aia.channels)):
        grp = hf[channel['name']]
        real_response = splev(T, channel['temperature_response_spline'])
        ax.plot(T, real_response, ls='-',color='k',)
        ax.plot(em.temperature, 
                np.array(grp['response'])[const_p_indices[:,0],const_p_indices[:,1]],
                color='k',ls='--',)
        elements = sorted([e for e in grp if e != 'response'],
                            key=lambda x: plasmapy.atomic.atomic_number(x))
        for j,element in enumerate(elements):
            ax.plot(em.temperature, 
                    np.array(grp[element])[const_p_indices[:,0],const_p_indices[:,1]],
                    color=PALETTE[j], ls='--', label=plasmapy.atomic.atomic_symbol(element),)
        if i==1:
            ax.legend(ncol=len(elements), loc="lower center", bbox_to_anchor=(0.5,1.02),
                      frameon=False)
        ax.text(6e7,1e-24, r'{} $\si{{\angstrom}}$'.format(channel['name']),
                fontsize=plt.rcParams['legend.fontsize'],
                horizontalalignment='right', verticalalignment='top')
ax.plot(T, p/T, color='k')

# Labels, limits
ax.set_xscale('log')
ax.set_yscale('log')
ax.set_ylim([2e-30,2e-24])
ax.set_xlim([1e5,8e7])
ax.set_yticks([1e-29, 1e-27, 1e-25])
axes[1,0].set_ylabel(r'$K_c$ $[\si{\dn\cm\tothe{5}\per\second\per\pixel}]$')
axes[1,0].set_xlabel(r'$T$ $[\si{\kelvin}]$')
plt.subplots_adjust(wspace=0.,hspace=0.)

# Save
tfig = ch6_modeling.save_figure('modeling-observables:aia-response', fext='.pgf')
tfig.caption = r'SSW temperature response functions (solid black) and effective temperature response functions for the elements in \autoref{tab:modeling-observables:elements} (dashed black) for all six EUV AIA channels. The colored, dashed curves, as indicated in the legend, denote the contributions of the individual elements to the total response. For this calculation, I have assumed equilibrium ionization and a constant pressure of \SI{e15}{\kelvin\per\cubic\cm}. The time-varying degradation of the instrument is not included.'
\end{pycode}
\py[chapter6_modeling]|tfig|
% spell-checker: enable %

When computing the intensity in each channel of AIA, the wavelength response functions are used  directly rather than relying on the temperature response functions computed by SolarSoft \citep[SSW,][]{freeland_data_1998}. As discussed in \autoref{sec:modeling-observables:atomic}, the assumption of ionization equilibrium is likely to be violated in the impulsive heating cases considered here. Thus, the contributions of each ion to the total channel response must be recomputed using the result of \autoref{eq:population_fraction_solution} in place of the equilibrium ion population fractions. \autoref{fig:modeling-observables:aia-response} shows the effective temperature response functions for the six AIA EUV channels compared to those calculated from \texttt{aia\_get\_response.pro} in SSW. Even though only a limited number of transitions from the CHIANTI database are included (see \autoref{tab:modeling-observables:elements}), nearly all of the response is recovered in each channel. The high-temperature contributions in the SSW results are due to continuum emission which is not included here. In all cases, the continuum contribution is several orders of magnitude below peak of the channel response. Additionally, the time variation in the wavelength response functions due to the degradation of the detector is not included \citep[see Section 2.1.6 of ][]{boerner_initial_2012}.

% spell-checker: disable %
\begin{pycode}[chapter6_modeling]
fig = plt.figure(figsize=texfigure.figsize(
    pytex,
    scale=0.65,
    height_ratio=1.0, 
))
ax = fig.gca()

min_T = 1e300*u.K
max_T = 0*u.K
p = 1e15*u.K/(u.cm**3)

i_loop=680
loop = ar.loops[i_loop]
for i,h in enumerate(heating):
    loop.parameters_savefile = os.path.join(ch6_modeling.data_dir, f'{h}', 'loop_parameters.h5')
    ax.plot(loop.electron_temperature[:,0], loop.density[:,0], color=PALETTE[i], alpha=0.75,
            label=h.split('_')[0].capitalize())
    min_T = min(min_T, loop.electron_temperature.min())
    max_T = max(max_T, loop.electron_temperature.max())
T = np.linspace(min_T,max_T,1000)
ax.plot(T, p/T, color='k')

ax.set_xscale('log')
ax.set_yscale('log')
ax.set_xlim(1.75e5,1e7)
ax.set_ylim(1.1e7,6e9)
ax.legend(ncol=3, loc="lower center", bbox_to_anchor=(0.5,1.02), frameon=False,)
ax.set_ylabel(r'$n$ $[\si{\per\cubic\cm}]$')
ax.set_xlabel(r'$T$ $[\si{\kelvin}]$')

tfig = ch6_modeling.save_figure('modeling-observables:hydro-phase-space', fext='.pgf')
tfig.caption = r'$n-T$ phase-space orbits for a single strand for the first three heating scenarios in \autoref{tab:modeling-observables:heating}. The black line indicates a constant pressure of $\SI{e15}{\kelvin\per\cubic\cm}$.'
tfig.figure_width = r'0.65\textwidth'
\end{pycode}
\py[chapter6_modeling]|tfig|
% spell-checker: enable %

Furthermore, during the evolution of a strand, the pressure is not constant for any of the heating scenarios as evidenced by \autoref{fig:modeling-observables:hydro-phase-space}. The black line of constant pressure $p=\SI{e15}{\kelvin\per\cubic\cm}$ shows the default pressure at which the SSW AIA response functions are evaluated. The other lines show the temperature-density phase space evolution for the high-, intermediate-, and low-frequency cases for a single strand, none of which is well described by the assumption of constant pressure.  Recomputing and interpolating the emissivity to the temperatures and densities as defined by the hydrodynamic simulation ensures that all quantities in \autoref{eq:modeling-observables:ppuv} are evaluated at the correct temperature and density.

\subsubsection{Mapping Back to the Magnetic Field}\label{sec:modeling-observables:mapping}

I compute the emissivity according to \autoref{eq:modeling-observables:ppuv} for all of the transitions in \autoref{tab:modeling-observables:elements} using the temperatures and densities from the hydrodynamic models for all $5\times10^3$ strands. I then compute the LOS integral in \autoref{eq:modeling-observables:intensity} by first converting the coordinates of each strand to a helioprojective (HPC) coordinate frame \citep[see][]{thompson_coordinate_2006} using the coordinate transformation functionality in Astropy \citep{the_astropy_collaboration_astropy_2018} combined with the solar coordinate frames provided by SunPy \citep{sunpy_community_sunpypython_2015}. Thus, the simulated \AR{} can easily be projected along any arbitrary LOS simply by changing the location of the observer that defines the HPC frame. Here, the HPC frame is defined by an observer at the position of the SDO spacecraft on 12 February 2011 15:32:42 UTC (i.e. the time of the HMI observation of NOAA 1158 shown in \autoref{fig:modeling-observables:magnetogram}). See \autoref{sec:coordinates} for a detailed discussion of solar coordinate systems.

Next, I compute a weighted two-dimensional histogram from the transformed coordinates, using the integrand of \autoref{eq:modeling-observables:intensity} at each coordinate as the weights. The histogram is constructed such that the bin widths are consistent with the spatial resolution of the instrument. For AIA, a single bin, representing a single pixel, has a width of \SI{0.6}{\arcsecond\per\pixel}. Finally, I  apply a Gaussian filter to the resulting histogram to emulate the point spread function of the instrument. This is done for each time step, using a cadence of \SI{10}{\second}, and for each channel. For every heating scenario, this produces approximately $6(3\times10^4)/10\approx2\times10^4$ separate images. This procedure is discussed in greater detail in \autoref{sec:instrument-effects}.

\section{Results}\label{sec:modeling-observables:results}

% spell-checker: disable %
\begin{pycode}[chapter6_results]
name = 'chapter6'
ch6_results = texfigure.Manager(
    pytex,
    os.path.join('.', name),
    number=6,
    **{k: os.path.join('.', name, v) for k,v in manager_opts.items()}
)
correlation_threshold = 0.1
rsquared_threshold = 0.75
channels = [94,131,171,193,211,335]
heating = [ 'high_frequency', 'intermediate_frequency', 'low_frequency' ]
channel_pairs = [(94,335), (94,171), (94,193),(94,131),(94,211),(335,131),(335,193),
				 (335,211),(335,171),(211,131),(211,171),(211,193),(193,171),(193,131),
				 (171,131),]
selected_channel_pairs = [channel_pairs[i] for i in (0, 9, 12)]
\end{pycode}
% spell-checker: enable %

I forward model time-dependent AIA intensities using the method outlined in \autoref{sec:modeling-observables:forward} for the heating scenarios given in \autoref{tab:modeling-observables:heating}. I discuss the predicted intensities in \autoref{sec:modeling-observables:intensities} for all six EUV channels of AIA and all five heating models. In \autoref{sec:modeling-observables:em_slopes} and \autoref{sec:modeling-observables:timelags}, I show the results of the emission measure and time lag analyses, respectively, applied to the simulated data. In \autoref{ch:classifying-observables},  these simulated observables are used to train a machine learning classification model to understand with which heating scenario the real data are most consistent.

\subsection{Intensities}\label{sec:modeling-observables:intensities}

I compute the intensities for the \SIlist{94;131;171;193;211;335}{\angstrom} channels of AIA using the procedure described in \autoref{sec:modeling-observables:forward}. The intensity in each pixel of the model \AR{} is computed for a total simulation period of $\SI{3e4}{\second}\approx\SI{8.3}{\hour}$ with the exception of the cooling case which is only run for \SI{e4}{\second}. For the high-, intermediate-, and low-frequency and ``random'' models, the first and last \SI{5e3}{\second} of evolution are discarded to avoid any transient effects in the strand evolution associated with the initial conditions and the constraints placed on the energy, respectively. I complete this procedure for each of the five heating scenarios in \autoref{tab:modeling-observables:heating}.

% spell-checker: disable %
\begin{pycode}[chapter6_results]
fig = plt.figure(figsize=texfigure.figsize(
    pytex,
    scale=1,
    height_ratio=0.5, 
    figure_width_context='figurewidth'
))
plt.subplots_adjust(hspace=0.03, wspace=0.03)
t = 1500
path_format = os.path.join(ch6_results.data_dir, '{}', 'map_t{:06d}_{}.fits')
for i,f in enumerate(heating):
    for j,c in enumerate(channels):
        m = Map(path_format.format(f,t,c))
        m = m.submap(SkyCoord(Tx=-390*u.arcsec,Ty=-325*u.arcsec,frame=m.coordinate_frame),
                     SkyCoord(Tx=-215*u.arcsec,Ty=-150*u.arcsec,frame=m.coordinate_frame))
        #ax = fig.add_subplot(6, 3, 3*j+i+1, projection=m)
        ax = fig.add_subplot(3, 6, 6*i+j+1, projection=m)
        norm = ImageNormalize(
            vmin=0,vmax=Map(path_format.format('low_frequency',t,c)).data.max(),
            stretch=SqrtStretch())
        im = m.plot(axes=ax, title=False, annotate=False, norm=norm)
        ax.grid(alpha=0)
        lon,lat = ax.coords
        lon.set_ticks(color='w', number=2)
        lat.set_ticks(color='w', number=2)
        lon.frame.set_linewidth(0)
        lat.frame.set_linewidth(0)
        if i==len(heating)-1 and j==1:
            lon.set_axislabel(r'Helioprojective Longitude',)
        else:
            lon.set_ticklabel_visible(False)
        if i==len(heating)-2 and j==0:
            lat.set_ticklabel(rotation='vertical')
            lat.set_axislabel(r'Helioprojective Latitude',)
        else:
            lat.set_ticklabel_visible(False)
        if j == 0:
            xtext,ytext = m.world_to_pixel(
                SkyCoord(-385*u.arcsec, -155*u.arcsec, frame=m.coordinate_frame))
            ax.text(xtext.value,ytext.value,f'{f.split("_")[0].capitalize()}',
                    color='w',fontsize=0.75*plt.rcParams['legend.fontsize'],
                    horizontalalignment='left', verticalalignment='top')
        if i == 0:
            xtext,ytext = m.world_to_pixel(
                SkyCoord(-220*u.arcsec, -320*u.arcsec, frame=m.coordinate_frame))
            ax.text(xtext.value, ytext.value, f'{c}' + r'\si{\angstrom}',
                    color='w', fontsize=0.75*plt.rcParams['legend.fontsize'],
                    horizontalalignment='right', verticalalignment='bottom')
            pos = ax.get_position().get_points()
            cax = fig.add_axes([pos[0,0], 0.89, pos[1,0]-pos[0,0], 0.025])
            cbar = fig.colorbar(im, cax=cax,orientation='horizontal')
            cbar.locator = matplotlib.ticker.MaxNLocator(nbins=3, prune='lower')
            cbar.ax.tick_params(labelsize=0.5*plt.rcParams['legend.fontsize'],width=0.5)
            cbar.update_ticks()
            cbar.ax.xaxis.set_ticks_position('top')
            cbar.outline.set_linewidth(0.5)
tfig = ch6_results.save_figure('modeling-observables:intensity-map', fext='.pdf')
tfig.caption = r'Snapshots of intensity, in \si{\dn\per\pixel\per\second}, across the whole \AR{} at $t=\SI{15e3}{\second}$. The rows correspond to the three different heating frequencies and the columns are the six EUV channels of AIA. In each column, the colorbar is on a square root scale and is normalized between zero and the maximum intensity in the low-frequency case. The color tables are the standard AIA color tables as implemented in SunPy \citep{sunpy_community_sunpypython_2015}.'
tfig.figure_width = r'\textwidth'
\end{pycode}
\py[chapter6_results]|tfig|
% spell-checker: enable %

\autoref{fig:modeling-observables:intensity-map} shows a snapshot of the intensity at $t=15\times10^3$ s for each channel and for the high-, intermediate-, and low-frequency nanoflare heating cases. The rows correspond to the different heating scenarios while the columns show the six channels. In each column, the intensities are normalized to the maximum intensity in the low-frequency case and are on a square root scale. In general, I find that in the high-frequency intensity maps, individual loops are difficult to distinguish while in the low-frequency case individual loops appear bright relative to the surrounding emission. This distinguishability or ``fuzziness'' can be measured quantitatively as $\sigma_{I}/\bar{I}$, where $\sigma_{I}$ is the standard deviation taken over all pixels and $\bar{I}$ is the mean intensity \citep[Equation 11]{guarrasi_coronal_2010}. A larger value of $\sigma_{I}/\bar{I}$ indicates a greater degree of contrast and vice versa. $\sigma_{I}/\bar{I}$ for each channel and heating frequency is shown in \autoref{tab:modeling-observables:fuzzy}. With the exception of 131 \AA{}, for every channel, the high-frequency case is the most ``fuzzy''. The low-frequency case shows the most contrast in each channel except 94 \AA{} though the margin between the low and intermediate cases is quite small in some cases.

% spell-checker: disable %
\begin{pycode}[chapter6_results]
# Define fuzziness function
def fuzzy(m):
    return np.sqrt(((
        m.data[np.where(m.data > 0)] - m.data[np.where(m.data > 0)].mean())**2)
        .sum()/m.data[np.where(m.data > 0)].size
    )/m.data[np.where(m.data > 0)].mean()

# Generate table
tab = Table({
    r'Channel $[\si{\angstrom}]$': channels,
    **{f.split('_')[0].capitalize(): [fuzzy(Map(path_format.format(f,t,c))) for c in channels]
        for f in heating}
})

# Write table to string
caption = r'$\sigma_I/\bar{I}$ as defined by Equation 11 of \citep{guarrasi_coronal_2010} computed on a single image at $t=\SI{15e3}{\second}$ for each channel and heating frequency. A larger value denotes a greater degree of contrast.\label{tab:modeling-observables:fuzzy}'
formats = {r'Channel $[\si{\angstrom}]$': '%.0f', **{f.split('_')[0].capitalize(): '%.2f' for f in heating}}
with io.StringIO() as f:
    astropy.io.ascii.write(
        tab,
        caption=caption,
        output=f,
        formats=formats,
        format='latex',
        latexdict = { 'data_start':r'\midrule', 'data_end': r'\bottomrule',
                      'header_start': r'\toprule', 'col_align': 'cccc',
                      'preamble':r'\begin{center}', 'tablefoot':r'\end{center}'},
    )
    table = f.getvalue()
\end{pycode}
\py[chapter6_results]|table|
% spell-checker: enable %

Looking at the first two columns of \autoref{fig:modeling-observables:intensity-map}, I find that the intensity in the \SIlist{94;131}{\angstrom} channels increases as the heating frequency decreases. Both channels are double peaked (see \autoref{fig:aia-temperature-response}) and have ``hot'' ($\approx\SI{7}{\mega\kelvin}$ for \SI{94}{\angstrom}, $\approx\SI{12}{\mega\kelvin}$ for \SI{131}{\angstrom}) and ``warm'' ($\approx\SI{1}{\mega\kelvin}$ for \SI{94}{\angstrom}, $\approx\SI{0.5}{\mega\kelvin}$ for \SI{131}{\angstrom}) components. In the case of high-frequency heating, less energy is available per event such that few strands are heated to $>\SI{4}{\mega\kelvin}$. There is little emission in the \SI{131}{\angstrom} channel as strands are not often permitted to cool to $\leq\SI{0.5}{\mega\kelvin}$ either. However, in the low- and intermediate-frequency cases, several individual bright loops appear in both the \SIlist{94;131}{\angstrom} channels as the heating rate is sufficient to produce ``hot'' (i.e. \SIrange{8}{10}{\mega\kelvin}) loops. Only a few of these loops are visible as the lifetime of this hot plasma is short due to the efficiency of thermal conduction. In contrast, the faint, diffuse component of the \SI{94}{\angstrom} emission that is present in all three cases is due to the contribution of the ``warm'' component. 

Additionally, I find that the \SI{171}{\angstrom} channel is dimmer for high-frequency heating as the peak sensitivity of this channel is $<\SI{1}{\mega\kelvin}$ and in the case of high-frequency heating, strands are rarely allowed to cool below \SI{1}{\mega\kelvin}. In contrast, the overall intensity in the \SIlist{193;211;335}{\angstrom} channels is relatively constant over heating frequency as compared to the three previous channels though individual loops do become more visible with decreasing heating frequency. This relative insensitivity is because the temperature response functions of these three channels all peak in between \SI{1.5}{\mega\kelvin} and \SI{2.5}{\mega\kelvin}. In the case of high-frequency heating, strands are being sustained near these temperatures while in the low-frequency case, strands are cooling through this temperature range. This is illustrated for a single strand in \autoref{fig:modeling-observables:hydro-profiles}.

While there are clear differences in the AIA intensities between all three heating frequencies, quantifying these differences is difficult due in part to the multidimensional nature of the intensity data. To better understand how observational signatures differ as a function of heating frequency, it is useful to find a reduced representation of the data that retains signatures of the underlying energy deposition. To this end, I compute two common observables: the emission measure slope (\autoref{sec:modeling-observables:em_slopes}) and the time lag (\autoref{sec:modeling-observables:timelags}).

\subsection{Emission Measure Slopes}\label{sec:modeling-observables:em_slopes}

As discussed in \autoref{sec:modeling-observables:introduction}, the emission measure slope is a useful quantity for understanding how frequently strands are re-energized. I compute emission measure distributions from the forward-modeled intensities using the regularized inversion method of \citet{hannah_differential_2012}. This method was designed to work with the narrowband coverage provided by AIA and so is well-suited to the data at hand. The temperature bins are chosen such that the leftmost edge is at \SI{e5.5}{\kelvin} and the rightmost edge at \SI{e7.2}{\kelvin} with bin widths of $\Delta\log T=0.1$. Rather than computing $\emd$ at each time step, I compute the time-averaged intensity in each pixel of each channel and compute $\emd$ only once. I compute the uncertainties on the intensities in each channel using the \texttt{aia\_bp\_estimate\_error.pro} procedure in SSW which incorporates uncertainties due to shot noise, read noise, dark subtraction, quantization, photometric calibration, and onboard compression. After computing $\emd$ in each pixel using the regularized inversion procedure, a first-order polynomial is fit to the log-transformed emission measure and temperature bin centers, $\log_{10}\mathrm{EM}\sim a\log_{10}T$, in order to calculate the emission measure slope, $a$. In \autoref{ch:classifying-observables}, I compare the modeled emission measure slopes to those derived from real AIA observations of NOAA 1158 using this same method.

% spell-checker: disable %
\begin{pycode}[chapter6_results]
fig = plt.figure(figsize=texfigure.figsize(
    pytex,
    scale=1,
    height_ratio=1/3,
))
params = {'cmap': 'viridis', 'vmin': 1.5, 'vmax': 7.5, 'title': False, 'annotate': False}
axes = []
for i,h in enumerate(heating):
    m = Map(os.path.join(ch6_results.data_dir, f'{h}', 'em_slope.fits'))
    m_r2 = Map(os.path.join(ch6_results.data_dir, f'{h}', 'em_slope_rsquared.fits'))
    m = Map(m.data, m.meta, mask=m_r2.data < rsquared_threshold)
    m = m.submap(SkyCoord(Tx=-405*u.arcsec,Ty=-335*u.arcsec,frame=m.coordinate_frame),
                 SkyCoord(Tx=-210*u.arcsec,Ty=-140*u.arcsec,frame=m.coordinate_frame))
    ax = fig.add_subplot(1, len(heating), i+1, projection=m)
    axes.append(ax)
    im = m.plot(axes=ax, **params)
    ax.grid(alpha=0)
    lon,lat = ax.coords
    lat.set_ticks(number=2)
    lon.set_ticks(number=3)
    if i > 0:
        lon.set_ticklabel_visible(False)
        lat.set_ticklabel_visible(False)
    else:
        lon.set_axislabel('Helioprojective Longitude',)
        lat.set_axislabel('Helioprojective Latitude',)
        lat.set_ticklabel(rotation='vertical')
    xtext,ytext = m.world_to_pixel(SkyCoord(-400*u.arcsec, -143*u.arcsec, frame=m.coordinate_frame))
    ax.text(xtext.value, ytext.value, h.split('_')[0].capitalize(),
            color='k', fontsize=plt.rcParams['legend.fontsize'],
            horizontalalignment='left', verticalalignment='top')
plt.subplots_adjust(hspace=0.03,wspace=0.03)
cax = fig.add_axes([
    axes[0].get_position().get_points()[0,0],
    axes[-1].get_position().get_points()[1,1]+0.02,
    axes[-1].get_position().get_points()[1,0] - axes[0].get_position().get_points()[0,0],
    0.04
])
cbar = fig.colorbar(im, cax=cax, orientation='horizontal');
cbar.ax.xaxis.set_ticks_position('top')
cbar.set_ticks([2,3,4,5,6,7])
cbar.ax.tick_params(width=0.5)
cbar.outline.set_linewidth(0.5)
tfig = ch6_results.save_figure('modeling-observables:em-slope-maps', fext='.pdf')
tfig.caption = r'Maps of the emission measure slope, $a$, in each pixel of the \AR{} for the high- (left), intermediate- (center), and low-frequency (right) cases. The $\emd$ is computed using time-averaged intensities from the six AIA EUV channels using the method of \citet{hannah_differential_2012}. The $\emd$ in each pixel is then fit to $T^a$ over the temperature range $\SI{8e5}{\kelvin}\le T< T_\textup{peak}$. Any pixels with $r^2<0.75$ are masked and colored white.'
\end{pycode}
\py[chapter6_results]|tfig|
% spell-checker: enable %

\autoref{fig:modeling-observables:em-slope-maps} shows the resulting emission measure slope, $a$, in each pixel of the forward-modeled \AR{} for the high-, intermediate-, and low-frequency cases. I fit $\emd$ over bins in the temperature range $\SI{8e5}{\kelvin}\le T< T_\textup{peak}$, where $T_\textup{peak}=\argmax_T\,\mathrm{EM}(T)$ is the temperature at which the emission measure distribution peaks. $r^2$, the correlation coefficient for the first-order polynomial fit, is used to assess the ``goodness-of-fit'' and pixels with $r^2<\py[chapter6_results]|rsquared_threshold|$ are masked. Looking at the three panels in \autoref{fig:modeling-observables:em-slope-maps}, overall $a$ tends to decrease with decreasing frequency, consistent with previous modeling work (see \autoref{sec:modeling-observables:introduction}). The low-frequency map (right panel) shows many values close to 2.

As the heating frequency increases, the slopes become larger, indicating an increasingly isothermal emission measure distribution. The intermediate-frequency map (center panel) shows predominantly higher slopes, with most pixels in the range $2\lesssim a \lesssim 3.5$ while the high-frequency map (left panel) shows much steeper slopes, most $a\ge3.5$, and a much broader range of slopes, $3\lesssim a \lesssim 8$. Note that in the high frequency case, the slope varies considerably across the \AR{} while the distribution of $a$ appears more spatially uniform in the intermediate- and low-frequency cases.

Below $T_\textup{peak}$, \citet{cargill_implications_1994} noted that the $\emd$ could be described by $\mathrm{EM}(T)\sim n^2\tau_{rad}$, where $\tau_{rad}\sim T^{1-\alpha}n^{-1}$ is the radiative cooling time. Additionally, \citet{bradshaw_cooling_2010} found that $T\sim n^{\ell}$, with $\ell\approx1$ for long loops and $\ell\approx2$ for short loops. Combining these expressions and assuming $\alpha=-1/2$ \citep{cargill_implications_1994} gives $a\approx2$ for short loops and $a\approx2.5$ for long loops in the case of single nanoflares. Emission measure slopes produced by low-frequency nanoflares as shown in the right panel of \autoref{fig:modeling-observables:em-slope-maps} are thus consistent with analytical results for single nanoflares.

% spell-checker: disable %
\begin{pycode}[chapter6_results]
fig = plt.figure(figsize=texfigure.figsize(
    pytex,
    scale=0.85,
    height_ratio=0.75,
))
ax = fig.gca()
params = {'bins': 'fd', 'histtype': 'step','density': True, 'lw': plt.rcParams['lines.linewidth']}
peaks = {}
for i,h in enumerate(heating):
    m = Map(os.path.join(ch6_results.data_dir, f'{h}', 'em_slope.fits'))
    m_rsquared = Map(os.path.join(ch6_results.data_dir, f'{h}', 'em_slope_rsquared.fits'))
    m = Map(m.data, m.meta, mask=m_rsquared.data < rsquared_threshold)
    hist, bins, _ = ax.hist(m.data[~m.mask], **params, color=PALETTE[i],
                            label=h.split('_')[0].capitalize())
    bin_centers = (bins[:-1] + bins[1:])/2
    peaks[h] = f'{bin_centers[np.argmax(hist)]:.1f}'

# Limits, labels
ax.set_xlim(1, 8);
ax.xaxis.set_major_locator(matplotlib.ticker.FixedLocator([2, 3, 4, 5, 6, 7]))
ax.yaxis.set_major_locator(matplotlib.ticker.MaxNLocator(nbins=7, prune='both'))
ax.legend(frameon=False, loc=1)
ax.set_xlabel(r'$a$')
ax.set_ylabel(r'Number of Pixels (Normalized)')

# Save
tfig = ch6_results.save_figure('modeling-observables:em-slope-histograms', fext='.pgf')
tfig.caption = r'Distribution of emission measure slopes, $a$, for every pixel in the simulated \AR{} for the high-, intermediate-, and low-frequency heating scenarios as shown in \autoref{fig:modeling-observables:em-slope-maps}. The histogram bins are determined using the Freedman Diaconis estimator \citep{freedman_histogram_1981} as implemented in the Numpy package for array computation in Python \citep{oliphant_guide_2006} and each histogram is normalized such that the area under the histogram is equal to 1.'
tfig.figure_width = r'0.85\textwidth'  
\end{pycode}
\py[chapter6_results]|tfig|
% spell-checker: enable %

\autoref{fig:modeling-observables:em-slope-histograms} shows histograms of the emission measure slopes for the high-, intermediate-, and low-frequency cases. I find that the low-frequency distribution peaks at $a\approx\py[chapter6_results]|peaks['low_frequency']|$, inside the range expected from analytical results (see above). The intermediate- and high-frequency distributions peak at successively higher values, $\approx\py[chapter6_results]|peaks['intermediate_frequency']|$ and $\approx\py[chapter6_results]|peaks['high_frequency']|$, respectively. While the low- and intermediate-frequency distributions are more narrowly distributed around their peak values, the distribution of slopes in the high-frequency case is relatively broad and has a positive skew towards steeper slopes. 

Looking at the distribution of slopes across the entire \AR{} in \autoref{fig:modeling-observables:em-slope-histograms}, I find that when the strands are heated infrequently (low frequency) such that each strand is allowed to cool fully prior to the next event, the distribution of slopes ``saturates'' in the range expected for single nanoflares. However, when the strands are reheated often (high frequency), the value of the slope becomes unsaturated and is subject to a range of infrequent cooling times due to the dependence of each waiting time on the power-law heating rate (see \autoref{sec:modeling-observables:heating}). These results are consistent with \citet{cargill_active_2014} who computed $\emd[T]=n^2L$ for a single strand for a range of heating frequencies and found $a$ converged to $\approx2$ for low-frequency nanoflares and increased slowly with increasing heating frequency.

The modeled emission measure slopes show that, even when accounting for the LOS integration, atomic physics, and information lost in the $\emd$ inversion, signatures of the heating frequency still persist in the emission measure slope. However, while this quantity retains information about the frequency of energy deposition, drawing conclusions about the heating based solely on the observed emission measure slope, particularly for a small number of pixels may be misleading. As shown here and in \citet{del_zanna_evolution_2015}, the slope may vary significantly across a given \AR{}. Additionally, calculating $\emd$ from observations is non-trivial due to several factors, including the mathematical difficulties of the ill-posed inversion \citep{craig_fundamental_1976,judge_failure_1995,judge_fundamental_1997}, uncertainties in the atomic data \citep{guennou_can_2013}, and insufficient constraints from spectroscopic observations \citep[e.g.][]{landi_isothermality_2010,winebarger_defining_2012}, among others.

\subsection{Time Lags}\label{sec:modeling-observables:timelags}

Next, I apply the time lag method of \citet{viall_evidence_2012} to the predicted intensities for each heating scenario in \autoref{tab:modeling-observables:heating}. For each pixel in the \AR{}, I compute the cross-correlation (\autoref{eq:cross_correlation_final}) for all pairs of AIA channels (15 in total) and find the temporal offset which maximizes the cross-correlation according to \autoref{eq:timelag}. The details of the cross-correlation and time lag calculation are given in \autoref{subsec:cross_correlation}. I consider all possible offsets over the interval $\pm\SI{6}{\hour}$. Using the convention of \citet{viall_evidence_2012}, the channel pairs are ordered such that the ``hot'' channel is listed first, meaning that a positive time lag corresponds to variability in the hotter channel followed by variability in the cooler channel. In other words, \textit{a positive time lag indicates cooling plasma.} For the \SI{94}{\angstrom} and \SI{131}{\angstrom} channels, both of which have a bimodal temperature response function (see \autoref{fig:aia-temperature-response}), the order is determined by the component which is most dominant such that \SI{94}{\angstrom} is ordered first while \SI{131}{\angstrom} is ordered second. Thus, it is possible for cooling plasma to produce negative time lags in these channel pairs and the ambiguity can be resolved in the context of the time lags in other channel pairs.

\subsubsection{Time-Lag Maps}\label{sec:modeling-observables:timelag_maps}

% spell-checker: disable %
\begin{pycode}[chapter6_results]
fig = plt.figure(figsize=texfigure.figsize(
    pytex,
    scale=1,
    height_ratio=3/5,
))

heating += ['random', 'cooling']
file_format = os.path.join(ch6_results.data_dir, '{}', '{}_{}_{}.fits')
norm = matplotlib.colors.Normalize(vmin=-(5e3*u.s).to(u.s).value,
                                   vmax=(5e3*u.s).to(u.s).value)
plot_params = { 'title': False, 'annotate': False, 'norm': norm, 'cmap': 'idl_bgry_004',}
selected_channel_pairs = [(94,335), (211,131), (193,171)]

for j,h in enumerate(heating):
    for i,cp in enumerate(selected_channel_pairs):
        m = Map(file_format.format(h, 'timelag', *cp))
        mc = Map(file_format.format(h, 'correlation', *cp))
        m = Map(m.data, m.meta, mask=np.where(mc.data<=correlation_threshold, True, False))
        m = m.submap(SkyCoord(Tx=-440*u.arcsec,Ty=-380*u.arcsec,frame=m.coordinate_frame),
                     SkyCoord(Tx=-185*u.arcsec,Ty=-125*u.arcsec,frame=m.coordinate_frame))
        ax = fig.add_subplot(len(selected_channel_pairs), len(heating), j+len(heating)*i+1,
                             projection=m)
        im = m.plot(axes=ax, **plot_params)
        ax.grid(alpha=0)
        lon = ax.coords[0]
        lat = ax.coords[1]
        lon.set_ticks(number=4)
        lat.set_ticks(number=4,) 
        if j == 0 and i == 1:
            lat.set_axislabel(r'Helioprojective Latitude',)
            lat.set_ticklabel(rotation='vertical',exclude_overlapping=True)
        else:
            lat.set_ticklabel_visible(False)
        if j == 1 and i == 2:
            lon.set_axislabel(r'Helioprojective Longitude',)
            lon.set_ticklabel(exclude_overlapping=True)
        else:
            lon.set_ticklabel_visible(False)
        if j == 0:
            xtext,ytext = m.world_to_pixel(SkyCoord(-435*u.arcsec, -130*u.arcsec, frame=m.coordinate_frame))
            ax.text(xtext.value, ytext.value, r'{}-{} $\si{{\angstrom}}$'.format(*cp),
                    color='k', fontsize=0.75*plt.rcParams['legend.fontsize'],
                    verticalalignment='top', horizontalalignment='left')
        if i == 0:
            xtext,ytext = m.world_to_pixel(SkyCoord(-435*u.arcsec, -375*u.arcsec, frame=m.coordinate_frame))
            ax.text(xtext.value, ytext.value, h.split('_')[0].capitalize(),
                    color='k', fontsize=0.75*plt.rcParams['legend.fontsize'],
                    verticalalignment='bottom', horizontalalignment='left')
        if i==0 and j==0:
            pos = ax.get_position().get_points()
            cax = fig.add_axes([pos[0,0], pos[1,1]+0.01, len(heating)*(pos[1,0]-pos[0,0] + 0.0215), 0.02])
            cbar = fig.colorbar(im, cax=cax, orientation='horizontal')
            cbar.ax.xaxis.set_ticks_position('top')
            cbar.ax.tick_params(width=0.5)
            cbar.outline.set_linewidth(0.5)
plt.subplots_adjust(wspace=0.03,hspace=0.03)

# Save
tfig = ch6_results.save_figure('modeling-observables:timelag-maps', fext='.pdf')
tfig.caption = r'Time lag maps for three different channel pairs for all five of the heating models described in \autoref{tab:modeling-observables:heating}. The value of each pixel indicates the temporal offset, in \si{\second}, which maximizes the cross-correlation (see \autoref{eq:timelag}). The rows indicate the different channel pairs and the columns indicate the varying heating scenarios. The range of the colorbar is $\pm\SI{5000}{\second}$. If $\max{\mathcal{C}_{AB}}<0.1$, the pixel is masked and colored white.'
tfig.figure_width = r'\textwidth'
\end{pycode}
\py[chapter6_results]|tfig|
% spell-checker: enable %

\autoref{fig:modeling-observables:timelag-maps} shows $\tau_{AB}$ (\autoref{eq:timelag}) in each pixel of the simulated \AR{} for all heating scenarios listed in \autoref{tab:modeling-observables:heating} and three selected channel pairs: 94-335, 211-131, and 193-171 \si{\angstrom}. Blacks, blues, and greens correspond to negative time lags; reds, oranges, and yellows correspond to positive time lags; and olive green indicates zero time lag. The range of the colorbar is $\pm\SI{5000}{\second}$. Note that the heating frequency decreases from left to right across each row. If the correlation in a given pixel is too low ($\max{\mathcal{C}_{AB}}<0.1$), the pixel is masked and colored white.

Looking at the first two rows of \autoref{fig:modeling-observables:timelag-maps}, I find that the positive time lags in the 211-131 \si{\angstrom} channel pair are significantly longer than those in the 94-335 \AA{} pair. In the temperature range $2.5<T<7.3\si{\mega\kelvin}$ (94-335 \si{\angstrom}), the dominant cooling mechanism is field-aligned thermal conduction while radiative cooling dominates in the range $0.6<T<2.5\si{\mega\kelvin}$ (211-131 \si{\angstrom}). Because thermal conduction is far more efficient at high temperatures, the plasma spends less time in the $[T_{335},T_{94}]$ temperature range than in $[T_{131},T_{211}]$. The 193-171 \si{\angstrom} time lags for the cooling case fall in the middle as radiative cooling also tends to dominate in this temperature interval ($0.9<T<1.5\si{\mega\kelvin}$), but the separation in temperature space is smaller than the 211-131 \si{\angstrom} pair. In all cases, these differences in the magnitude of the positive time lags become more apparent at lower heating frequencies.

In the 94-335 \si{\angstrom} pair, I find negative time lags in the longest loops near the edge of the \AR{}, inconsistent with the previous assertion that longer loops lead to longer, positive time lags. These loops are rooted in areas of weaker magnetic field (compared to the center) and thus do not have sufficient energy to evolve significantly into the temperature range of the ``hot'' component of the 94 \si{\angstrom} channel (see \autoref{sec:modeling-observables:heating}). Thus, cooling from 335 \si{\angstrom} to the cooler part of 94 \si{\angstrom} dominates the cross-correlation. These negative time lags become more prominent as the heating frequency decreases. The results in the cooling case are consistent with the negative 94-335 \si{\angstrom} time lags of similar magnitude observed by \citet{viall_survey_2017} in this same \AR{} and the tendency for longer field lines to exhibit cooler plasma, though \citeauthor{viall_survey_2017} found far fewer positive 94-335 \si{\angstrom} time lags.

I also find negative 211-131 \si{\angstrom} time lags in the center of the \AR{} for the high-, intermediate-, and low-frequency cases, indicative of plasma cooling from the hot part of the 131 \si{\angstrom} channel through the 211 \si{\angstrom} channel. Though they are not shown here, similar negative time lag signatures are present in nearly all of the other 131 \si{\angstrom} channel pairs as well. These results are consistent with that of \citet{cadavid_heating_2014} who found that in inter-moss regions of \AR{} NOAA 11250, intensity variations in the 131 \si{\angstrom} channel preceded brightenings in all other EUV channels. In the two control cases, I do not find any negative time lags as the cross-correlations in the core are dominated by uninterrupted cooling from \SI{211}{\angstrom} to the cool part of \SI{131}{\angstrom}.

For the 193-171 \si{\angstrom} channel pair, I find very few negative time lags because, unlike the \SIlist{94;131}{\angstrom} channels, the \SIlist{193;171}{\angstrom} channels are strongly peaked about a single temperature. Along with 211 \si{\angstrom}, these channels are important for disambiguating the signals in channels with a bimodal temperature response function.

These simulated time lags show far fewer zero time lags than the observations of \citet{viall_evidence_2012,viall_survey_2017} and the modeling work of \citet{bradshaw_patterns_2016} due to the lack of TR emission in the model. As shown by \citet{viall_transition_2015}, TR emission shows near-zero time lags because every layer (or temperature) of the TR responds in unison. However, for the 193-171 \si{\angstrom} channel pair, I find that zero time lags still dominate the inner core of the \AR{} for all five heating scenarios, suggesting that the plasma is cooling into, but not through the \SI{171}{\angstrom} temperature bandpass \citep{viall_survey_2017}. This underscores the point that zero time lags do not imply steady heating \citep{viall_transition_2015,viall_signatures_2016}.

\subsubsection{Cross-Correlation Maps}\label{sec:modeling-observables:cross_correlation_maps}

% spell-checker: disable %
\begin{pycode}[chapter6_results]
fig = plt.figure(figsize=texfigure.figsize(
    pytex,
    scale=1,
    height_ratio=3/5,
))

plot_params = {'title': False, 'annotate': False, 'vmin': 0, 'vmax': 1, 'cmap': 'magma',}
for j,h in enumerate(heating):
    for i,cp in enumerate(selected_channel_pairs):
        m = Map(file_format.format(h, 'correlation', *cp))
        m = m.submap(SkyCoord(Tx=-440*u.arcsec,Ty=-380*u.arcsec,frame=m.coordinate_frame),
                     SkyCoord(Tx=-185*u.arcsec,Ty=-125*u.arcsec,frame=m.coordinate_frame))
        ax = fig.add_subplot(len(selected_channel_pairs), len(heating), j+len(heating)*i+1,
                             projection=m)
        im = m.plot(axes=ax, **plot_params)
        ax.grid(alpha=0)
        lon = ax.coords[0]
        lat = ax.coords[1]
        lon.set_ticks(number=4,color='w')
        lat.set_ticks(number=4,color='w')
        lon.frame.set_linewidth(0)
        lat.frame.set_linewidth(0)
        if j == 0 and i == 1:
            lat.set_axislabel(r'Helioprojective Latitude',)
            lat.set_ticklabel(rotation='vertical',exclude_overlapping=True)
        else:
            lat.set_ticklabel_visible(False)
        if j == 1 and i == 2:
            lon.set_axislabel(r'Helioprojective Longitude',)
            lon.set_ticklabel(exclude_overlapping=True)
        else:
            lon.set_ticklabel_visible(False)
        if j == 0:
            xtext,ytext = m.world_to_pixel(SkyCoord(-435*u.arcsec, -130*u.arcsec, frame=m.coordinate_frame))
            ax.text(xtext.value, ytext.value, r'{}-{} $\si{{\angstrom}}$'.format(*cp),
                    color='w', fontsize=0.75*plt.rcParams['legend.fontsize'],
                    verticalalignment='top', horizontalalignment='left')
        if i == 0:
            xtext,ytext = m.world_to_pixel(SkyCoord(-435*u.arcsec, -375*u.arcsec, frame=m.coordinate_frame))
            ax.text(xtext.value, ytext.value, h.split('_')[0].capitalize(),
                    color='w', fontsize=0.75*plt.rcParams['legend.fontsize'],
                    verticalalignment='bottom', horizontalalignment='left')
        if i==0 and j==0:
            pos = ax.get_position().get_points()
            cax = fig.add_axes([pos[0,0], pos[1,1]+0.01, len(heating)*(pos[1,0]-pos[0,0] + 0.0215), 0.02])
            cbar = fig.colorbar(im, cax=cax, orientation='horizontal')
            cbar.ax.xaxis.set_ticks_position('top')
            cbar.ax.tick_params(width=0.5)
            cbar.outline.set_linewidth(0.5)
plt.subplots_adjust(wspace=0.03, hspace=0.03)

# Save
tfig = ch6_results.save_figure('modeling-observables:correlation-maps', fext='.pdf')
tfig.caption = r'Same as \autoref{fig:modeling-observables:timelag-maps} except each pixel shows the maximum cross-correlation, $\max\mathcal{C}_{AB}$.'
\end{pycode}
\py[chapter6_results]|tfig|
% spell-checker: enable %

\autoref{fig:modeling-observables:correlation-maps} shows the peak cross-correlation value, $\max\mathcal{C}_{AB}$, for each selected channel pair. Looking first at all three channel pairs, the cross-correlation, on average, increases as the heating frequency decreases. Additionally, the highest cross-correlations tend to be in the center of the \AR{} while the lowest tend to be on the outer edge. Comparing \autoref{fig:modeling-observables:correlation-maps} with the time lags in \autoref{fig:modeling-observables:timelag-maps} also reveals that negative time lags are correlated with lower peak cross-correlation values. Furthermore, other than the ``cooling'' scenario, there are large variations from one loop to the next for all heating frequencies such that the spatial coherence of these peak cross-correlation values is low. In \autoref{ch:classifying-observables}, I use the peak cross-correlation value, in addition to the time lag, to classify the heating frequency in each observed pixel.

\subsubsection{Histograms}\label{sec:modeling-observables:histograms}

\autoref{fig:modeling-observables:timelag-histograms} shows histograms of time lags for every channel pair and all five heating scenarios. The time lags are binned between \SI{-e4}{\second} and \SI{e4}{\second} in \SI{60}{\second} bins. Each histogram is colored according the corresponding heating function, consistent with \autoref{fig:modeling-observables:hydro-profiles} and \autoref{fig:modeling-observables:em-slope-histograms}. The columns are arranged such that heating frequency decreases from left to right. Every channel pair and every heating model is shown in order to demonstrate how the distribution of time lags evolves as the heating frequency varies.

Note that as the frequency decreases (from left to right), the number of negative time lags decreases. In the ``cooling'' case, there are very few negative time lags except for channel pairs which include one or both of the double-peaked channels (\SIlist{94;131}{\angstrom}). For those channel pairs which include \SI{94}{\angstrom} and/or \SI{131}{\angstrom}, negative time lags are expected, even in the single-nanoflare cooling case as the convention of ordering the ``hot'' channel first has been violated such that cooling plasma can lead to negative time lags. For the remaining channel pairs, negative time lags are associated with the heating and cooling cycle being interrupted by repeated events on a given strand.

% spell-checker: disable %
\begin{pycode}[chapter6_results]
fig,axes = plt.subplots(
    len(channel_pairs), len(heating),
    figsize=texfigure.figsize(
        pytex,
        scale=1,
        height_ratio=1.0,
))
bins = np.arange((-10e3*u.s).value, (10e3*u.s).value, (60*u.s).value)
plot_params = { 'histtype':'step', 'bins':bins, 'log':True, 'lw': 1}

for i,cp in enumerate(channel_pairs):
    for j,h in enumerate(heating):
        ax = axes[i,j]
        # Select Map and Mask
        m = Map(file_format.format(h, 'timelag', *cp))
        mc = Map(file_format.format(h, 'correlation', *cp))
        m = Map(m.data, m.meta, mask=np.where(mc.data<=correlation_threshold, True, False))
        hist, bins, _ = ax.hist(m.data[~m.mask].flatten(), **plot_params, color=PALETTE[j])
        ax.axvline(x=0, ls=':', alpha=0.75, color='k', lw=1)
        # Channel and Heating Labels
        if j==0 and (i+1)%2 != 0:
            ax.set_ylabel('{}-{}'.format(*cp), fontsize=plt.rcParams['ytick.labelsize'])
        if j==len(heating)-1 and (i+1)%2 == 0:
            ax.set_ylabel('{}-{}'.format(*cp), fontsize=plt.rcParams['ytick.labelsize'])
            ax.yaxis.set_label_position('right')
        if i==0:
            ax.set_title(h.split('_')[0].capitalize())
        # Limits
        ax.set_ylim(2, 1e5)
        ax.set_xlim(1.1*bins[0], 1.1*bins[-1])
        # Spines and limits
        if j > 0:
            ax.spines['left'].set_visible(False)
            ax.tick_params(axis='y', which='both', length=0, labelleft=False)
        else:
            if i < len(channel_pairs) - 1:
                ax.tick_params(axis='y', which='both', labelleft=False)
        if j < len(heating)-1:
            ax.spines['right'].set_visible(False)
        if i > 0:
            ax.spines['top'].set_visible(False)
        if i < len(channel_pairs)-1:
            ax.spines['bottom'].set_visible(False)
            ax.tick_params(axis='x',which='both',length=0,labelbottom=False)
        else:
            if j > 0:
                ax.tick_params(axis='x', which='both', labelbottom=False)
axes[len(channel_pairs)-1,0].set_xlabel(r'$\tau_{AB}$ $[\si{\second}]$')
plt.subplots_adjust(hspace=0,wspace=0)

# Save
tfig = ch6_results.save_figure('modeling-observables:timelag-histograms', fext='.pgf')
tfig.caption = r'Histograms of time lag values across the whole \AR{}. The rows indicate the different channel pairs and the columns indicate the different heating models. Colors are used to denote the various heating models. The black dashed line denotes zero time lag. The bin range is $\pm\SI{e4}{\second}$ and the bin width is \SI{60}{\second}. As with the time-lag maps, time lags corresponding to $\max{\mathcal{C}_{AB}}<0.1$ are excluded.'
tfig.placement = '!h'
\end{pycode}
\py[chapter6_results]|tfig|
% spell-checker: enable %

\section{Discussion}\label{sec:modeling-observables:discussion}

For all of the heating models, I find negative time lags in at least one of the three channel pairs as shown in \autoref{fig:modeling-observables:timelag-maps}. Negative time lags can be used to disambiguate the temperature sensitivity of the AIA passbands and can be produced in one of two ways: high-frequency heating in which the time lag is dominated by many frequent reheatings or a channel pair in which one channel is bimodal. While intensity in the \SI{131}{\angstrom} channel can correspond to either $\SI{0.4}{\mega\kelvin}$ or $>\SI{10}{\mega\kelvin}$ plasma (see \autoref{fig:aia-temperature-response}), negative time lags in the 211-131 \si{\angstrom} channel pair provide a possible signature of $\ge\SI{10}{\mega\kelvin}$ plasma because a negative time lag implies the plasma is cooling from \SI{131}{\angstrom} to \SI{211}{\angstrom}. This also holds for the 171-131 and 193-131 \si{\angstrom} channel pairs as well while the 94-131 and 335-131 \si{\angstrom} channels are more ambiguous due to the first channel in the pair being bimodal as well. As noted in \autoref{sec:modeling-observables:timelag_maps}, the high-, intermediate-, and low-frequency maps for the 211-131 \si{\angstrom} channel pair all show coherent negative time lags in the core. Because these strands are rooted in areas of strong field, enough energy is made available by the field (see \autoref{sec:modeling-observables:heating}) to heat them well into (and likely above) the hot component of the \SI{131}{\angstrom} passband. Since these strands are relatively short, the density increases rapidly enough for this hot plasma to be visible before it is washed out by thermal conduction.

Plasma undergoing pure cooling by radiation and thermal conduction produces a predictable and well-understood time lag signature. However, complicated heating scenarios and LOS geometries are likely to make it more difficult to interpret observed time lag signatures. Consider the case of a single cooling strand such that the maximum allowed time lag for a given channel pair $AB$ is the amount of time it takes to cool from $T_A$ to $T_B$ by thermal conduction and radiation. The ``cooling'' case in \autoref{fig:modeling-observables:timelag-histograms} may be regarded as the baseline time lag distribution given that all strands were heated only once at $t=\SI{0}{\second}$. Because the time lag is primarily determined by the cooling phase of the strand, the time lag becomes primarily a function of the loop length $L$ since $\tau_\textup{cool}\propto L$. Two effects are likely to increase the decoherence of the baseline time lag distribution: multiple structures evolving out-of-phase along a given LOS (the ``random'' heating scenario) and multiple reheatings before the end of the cooling and draining cycle on a given strand. Note that multiple polluting structures along the LOS seem to primarily add negative time lags to the distribution (the ``random'' case) while increasing the frequency of events on a given strand extends the distribution in the positive direction. The latter effect also produces more negative time lags. Since steady heating can be thought of as nanoflare heating in the high-frequency limit, the distribution of time lags is expected to approach a uniform distribution as the heating frequency increases. This is again consistent with the results of \citet{viall_signatures_2016} who found that steadily-heated loops have no preferred time lag.

While the model for the energy deposition presented here (see \autoref{sec:modeling-observables:heating}) does not assume any specific physical heating mechanism, the parameterization of the heating frequency in \autoref{eq:modeling-observables:heating_types} has an interesting implication in the context of the \citet{parker_nanoflares_1988} nanoflare model. Rearranging \autoref{eq:modeling-observables:heating_types} and recalling that $\tau_\textup{cool}\propto L$ gives $\langle\twait\rangle\propto L$, i.e. longer strands have longer absolute waiting times between heating events. Given that longer field lines tend to be rooted in regions of weaker magnetic field, this further implies that, where the field is stronger, energy is more quickly dissipated. According to \citet{parker_nanoflares_1988}, this dissipation is due to small-scale reconnection of flux tubes that are continually stressed by the convective motion of the underlying photosphere. Thus, in this context, this heating model implies that the reconnection and the underlying driver are more efficient in areas where the field is strongest.

Though I have not addressed it here, another possible mechanism for producing time-varying intensity in \AR s is thermal non-equilibrium (TNE) wherein condensation cycles driven by highly-stratified, but steady footpoint heating lead to long-period intensity pulsations \citep{kuin_thermal_1982}. Though originally used to explain coronal rain \citep{antolin_coronal_2010,antolin_multithermal_2015,auchere_coronal_2018} and prominences \citep{antiochos_model_1991}, several workers \citep{mok_three-dimensional_2016,winebarger_investigation_2016,froment_long-period_2017,winebarger_identifying_2018,froment_occurrence_2018} have recently claimed that TNE can produce time lag signatures similar to those of impulsive heating models, suggesting that observed time lags may be consistent with both impulsive and steady heating. However, it is not yet clear whether TNE is consistent with observed signatures of very hot (8-10 MK) plasma. Detailed comparisons between TNE and nanoflare simulations and observations are desperately needed. See \autoref{sec:tne} for additional discussion on TNE as a possible model for explaining observed \AR{} variability.

\section{Summary}\label{sec:modeling-observables:conclusions}

I have carried out a series of numerical simulations in an effort to understand how signatures of the nanoflare heating frequency are manifested in two observables: the emission measure slope and the time lag. For a given magnetogram observation of the relevant \AR{} (in this case, NOAA 1158), I compute a potential field extrapolation and trace a large number of field lines through the extrapolated vector field. For each traced field line, an EBTEL hydrodynamic simulation is run and the resulting temperatures and densities, combined with data from CHIANTI and the instrument response function, are used to compute the time-dependent intensity. These intensities are then mapped back to the magnetic skeleton and integrated along the LOS in each pixel to create time-dependent images of the \AR{}.

Using the novel and efficient forward modeling pipeline, I produced AIA images for all six EUV channels for $\approx\SI{8}{\hour}$ of simulation time. From these results, I computed both the emission measure slope and the time lag for all possible channel pairs for three different nanoflare heating frequencies, high, intermediate, and low, (see \autoref{eq:modeling-observables:heating_types}) in addition to two control models, for a total of five different heating scenarios (see \autoref{tab:modeling-observables:heating}).

The results of this study can be summarized in the following points:
\begin{enumerate}
    \item As the heating frequency decreases, the emission measure slope, $a$, becomes increasingly shallow, saturating at $a\approx2$. As the heating frequency increases, the distribution of slopes over the \AR{} is shifted to higher values and broadens.
    \item The time lag becomes increasingly spatially coherent with decreasing heating frequency. When strands are allowed to cool without being re-energized, the spatial distribution of time lags is largely determined by the distribution of loop lengths over the \AR{}.
    \item The distribution of time lags becomes increasingly broad and approaches a uniform distribution as the heating frequency increases, consistent with the results of \citet{viall_signatures_2016}.
    \item Negative time lags in channel pairs where the second (``cool'') channel is \SI{131}{\angstrom} provide a possible diagnostic for $\ge\SI{10}{\mega\kelvin}$ plasma
\end{enumerate}

In this chapter, I have used the advanced forward modeling pipeline, as described in \autoref{ch:synthesizar}, to systematically examine how the emission measure slope and time lag are affected by the nanoflare heating frequency. In \autoref{ch:classifying-observables} I use the model results presented here to train a random forest classification model and apply it to emission measure slopes and time lags derived from real AIA observations of NOAA 1158. The 15 channel pairs for the time lag and cross-correlation combined with the emission measure slope represent a 31-dimensional feature space and a single 500-by-500 pixel \AR{} amounts to $2.5\times10^5$ sample points. Performing an accurate assessment over this amount of data manually or ``by eye'' is at least impractical and likely impossible. Thus, the application of machine learning to the problem of assessing models in the context of real data is a critical step in understanding the underlying energy deposition in \AR{} cores. 
